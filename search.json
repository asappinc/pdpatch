[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pdpatch",
    "section": "",
    "text": "pdpatch adds methods to pandas’ DataFrame and Series for a faster data science pipeline. It also defines drop-in replacements for seaborn and plotly.express that automatically label axes with nicer titles. We use nbdev to build this project."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "pdpatch",
    "section": "Install",
    "text": "Install\npip install pdpatch"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "pdpatch",
    "section": "How to use",
    "text": "How to use\n\nfrom pdpatch.all import *\n\n\nInteractive Method .less()\n\n\n\nAlt Text\n\n\n\n\nAutomatically Rename snake_case columns in plotly.express and seaborn\n\nimport pandas as pd\nfrom pdpatch.express import *\ndf = pd.DataFrame({'time__s__': range(10), 'position__m__': [i**1.3 for i in range(10)], 'speed__m/s__': 10*[1]})\n#df = pd.DataFrame({'time__s__': range(10), 'position__m__': range(10)})\npx.scatter(df, x='time__s__', y='position__m__').show('png')\n\n\n\n\n\nfrom pdpatch.seaborn import sns\nsns.scatterplot(data=df, x='time__s__', y='position__m__');\n\n\n\n\n\n\nAdd Altair-like Operation to plotly Figures\n\nfig = px.scatter(df,x='time__s__', y='time__s__') | px.scatter(df,x='time__s__', y=['position__m__', 'speed__m/s__'])\nfig.show('png')\n\n\n\n\n\nfig = px.scatter(df,x='time__s__', y='time__s__') / px.scatter(df,x='time__s__', y=['position__m__', 'speed__m/s__'])\nfig.show('png')\n\n\n\n\n\nfig = px.scatter(df,x='time__s__', y='time__s__') | px.scatter(df,x='time__s__', y=['position__m__', 'speed__m/s__'])\n(fig / fig).show('png')\n\n\n\n\n\n\nShorter methods\ndf.rename(columns={'col_1': 'new_name'})->df.renamec('col_1', 'new_name')\n\ndf = dummydf()\ndf.renamec('col_1', 'new_name').to_html()\n\n\n\n\n\n\n\n\n\n\n\n\nnew_name\n\n\n\ncol_2\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n\n100\n\n\n\na\n\n\n\n\n\n\n\n1\n\n\n\n101\n\n\n\nb\n\n\n\n\n\n\n\n2\n\n\n\n102\n\n\n\nc\n\n\n\n\n\n\n\n3\n\n\n\n103\n\n\n\nd\n\n\n\n\n\n\n\n4\n\n\n\n104\n\n\n\ne\n\n\n\n\n\n\n\n\n\n\n\n\nFunctions as methods\n\ndf.len()\n\n5\n\n\n\n\nNew methods\n\ndf.col_1.minmax\n\n(100, 104)\n\n\n\n\nUtility functions\n\ndf = dummydf()\ndf.to_html()\n\n\n\n\n\n\n\n\n\n\n\n\ncol_1\n\n\n\ncol_2\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n\n100\n\n\n\na\n\n\n\n\n\n\n\n1\n\n\n\n101\n\n\n\nb\n\n\n\n\n\n\n\n2\n\n\n\n102\n\n\n\nc\n\n\n\n\n\n\n\n3\n\n\n\n103\n\n\n\nd\n\n\n\n\n\n\n\n4\n\n\n\n104\n\n\n\ne"
  },
  {
    "objectID": "05_transformer.html",
    "href": "05_transformer.html",
    "title": "pdpatch",
    "section": "",
    "text": "source\n\nDataFrameTransformer\n\n DataFrameTransformer (transformer=None, input_cols=None,\n                       output_cols=None, prev_step=None, append=False,\n                       print_input_cols=False, print_output_cols=False,\n                       print_out_df_cols=False)\n\nApplies a transformer to a set of columns of pandas DataFrame and it outputs a DataFrame too.\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\n\n\nX = pd.DataFrame(\n    {'city': ['London', 'London', 'Paris', 'Sallisaw'],\n     'title': [\"His Last Bow\", \"How Watson Learned the Trick\",\n               \"A Moveable Feast\", \"The Grapes of Wrath\"],\n     'expert_rating': [5, 3, 4, 5],\n     'user_rating': [4, 5, 4, 3]})\nX\n\n\n\n\n\n  \n    \n      \n      city\n      title\n      expert_rating\n      user_rating\n    \n  \n  \n    \n      0\n      London\n      His Last Bow\n      5\n      4\n    \n    \n      1\n      London\n      How Watson Learned the Trick\n      3\n      5\n    \n    \n      2\n      Paris\n      A Moveable Feast\n      4\n      4\n    \n    \n      3\n      Sallisaw\n      The Grapes of Wrath\n      5\n      3\n    \n  \n\n\n\n\nThe OneHotEncoder expects a two dimensional array as input, so we set the input_cols to a list of columns. DataFrameTransformer uses the\n\nenc_city = DataFrameTransformer(transformer=OneHotEncoder(dtype='int'),\n                                input_cols=['city'],\n                                append=True)\nenc_city.fit_transform(X)\n\n\n\n\n\n  \n    \n      \n      city\n      title\n      expert_rating\n      user_rating\n      city_London\n      city_Paris\n      city_Sallisaw\n    \n  \n  \n    \n      0\n      London\n      His Last Bow\n      5\n      4\n      1\n      0\n      0\n    \n    \n      1\n      London\n      How Watson Learned the Trick\n      3\n      5\n      1\n      0\n      0\n    \n    \n      2\n      Paris\n      A Moveable Feast\n      4\n      4\n      0\n      1\n      0\n    \n    \n      3\n      Sallisaw\n      The Grapes of Wrath\n      5\n      3\n      0\n      0\n      1\n    \n  \n\n\n\n\nCountVectorizer expects a one-dimensional array as input so we set input_cols to a string that will retrieve a one-dimensional array from the input DataFrame.\n\nenc_title = DataFrameTransformer(transformer=CountVectorizer(), input_cols='title', append=True)\nenc_title.fit_transform(X)\n\n\n\n\n\n  \n    \n      \n      city\n      title\n      expert_rating\n      user_rating\n      bow\n      feast\n      grapes\n      his\n      how\n      last\n      learned\n      moveable\n      of\n      the\n      trick\n      watson\n      wrath\n    \n  \n  \n    \n      0\n      London\n      His Last Bow\n      5\n      4\n      1\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      London\n      How Watson Learned the Trick\n      3\n      5\n      0\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      1\n      1\n      1\n      0\n    \n    \n      2\n      Paris\n      A Moveable Feast\n      4\n      4\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      Sallisaw\n      The Grapes of Wrath\n      5\n      3\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n      0\n      1\n    \n  \n\n\n\n\nWe can chain these two into one Pipeline.\n\npipe = Pipeline([('enc_city', enc_city), ('enc_title', enc_title)])\npipe.fit_transform(X)\n\n\n\n\n\n  \n    \n      \n      city\n      title\n      expert_rating\n      user_rating\n      city_London\n      city_Paris\n      city_Sallisaw\n      bow\n      feast\n      grapes\n      his\n      how\n      last\n      learned\n      moveable\n      of\n      the\n      trick\n      watson\n      wrath\n    \n  \n  \n    \n      0\n      London\n      His Last Bow\n      5\n      4\n      1\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      London\n      How Watson Learned the Trick\n      3\n      5\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      1\n      0\n      0\n      1\n      1\n      1\n      0\n    \n    \n      2\n      Paris\n      A Moveable Feast\n      4\n      4\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      Sallisaw\n      The Grapes of Wrath\n      5\n      3\n      0\n      0\n      1\n      0\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n      0\n      1"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\n\n\n dummydf ()\n\nA dummy DataFrame."
  },
  {
    "objectID": "core.html#transformations",
    "href": "core.html#transformations",
    "title": "core",
    "section": "Transformations",
    "text": "Transformations\n\n\nDataFrame.repetitions\n\n DataFrame.repetitions (col)\n\nCounts the number of repetitions for each element.\n\ndf = pd.DataFrame({'a': [1, 2, 3, 4, 4, 5, 5, 6, 6, 6], 'b':[1, 1, 1, 1, 2, 2, 2, 3, 3, 4]})\ndf.repetitions('b')\n\nb\n1    4\n2    3\n3    2\n4    1\ndtype: int64\n\n\n\ntest(df.repetitions('b'), pd.Series({1:4, 2:3,3:2, 4:1}), all_equal)\n\n\n\n\nDataFrame.repetition_counts\n\n DataFrame.repetition_counts (col)\n\nCounts the number of groups with the same number of repetitions.\nIn the following example there are three groups with one element, two groups with two elements, and one group with three elements.\n\ndf.repetition_counts('a')\n\n1    3\n2    2\n3    1\ndtype: int64\n\n\n\ntest(df.repetition_counts('a'), pd.Series({1: 3, 2:2, 3:1}), all_equal)\n\n\n\n\nDataFrame.single_events\n\n DataFrame.single_events (col)\n\n\n\n\nDataFrame.single_events\n\n DataFrame.single_events (col)\n\nReturns rows that appear only once.\n\ndf.single_events('a')\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      1\n      1\n    \n    \n      1\n      2\n      1\n    \n    \n      2\n      3\n      1\n    \n  \n\n\n\n\n\ntest_eq(df.single_events('a'), df.loc[[0, 1, 2]])"
  },
  {
    "objectID": "core.html#functions-as-methods",
    "href": "core.html#functions-as-methods",
    "title": "core",
    "section": "Functions as methods",
    "text": "Functions as methods\nPandas functions that are easier to execute as DataFrame/Series methods.\n\n\nDataFrame.crosstab\n\n DataFrame.crosstab (index, column, **kwargs)\n\n\n\n\nDataFrame.len\n\n DataFrame.len ()\n\n\n\n\nSeries.len\n\n Series.len ()"
  },
  {
    "objectID": "core.html#one-liners",
    "href": "core.html#one-liners",
    "title": "core",
    "section": "One-liners",
    "text": "One-liners\n\nThese methods allow fast exploration of the data in one line.\n\n\n\nIndex.l\n\n Index.l ()\n\n\n\n\nSeries.minmax\n\n Series.minmax ()\n\n\n\n\nDataFrame.page\n\n DataFrame.page (page, page_size=5)\n\nShows rows between page*page_size and (page+1)*page_size\n\ndf = pd.DataFrame({'a': range(12), 'b': range(12)})\ndf.page(3)\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      10\n      10\n      10\n    \n    \n      11\n      11\n      11\n    \n  \n\n\n\n\n\n\n\nSeries.page\n\n Series.page (page, page_size=5)\n\nShows rows between page*page_size and (page+1)*page_size\n\ns = pd.Series(range(15))\ns.page(2)\n\n5    5\n6    6\n7    7\n8    8\n9    9\ndtype: int64\n\n\n\nsource\n\n\nL.page\n\n L.page (page, page_size=10)\n\nShows elements between page*page_size and (page+1)*page_size"
  },
  {
    "objectID": "core.html#method-variations",
    "href": "core.html#method-variations",
    "title": "core",
    "section": "Method Variations",
    "text": "Method Variations\nThese methods are slight variations from DataFrame ones.\n\n\nDataFrame.renamec\n\n DataFrame.renamec (d, *args, **kwargs)\n\n\ndf = dummydf()\ndf.renamec({'col_1': 'col_a'}, 'col_2', 'bar')\n\n\n\n\n\n  \n    \n      \n      col_a\n      bar\n    \n  \n  \n    \n      0\n      100\n      a\n    \n    \n      1\n      101\n      b\n    \n    \n      2\n      102\n      c\n    \n    \n      3\n      103\n      d\n    \n    \n      4\n      104\n      e\n    \n  \n\n\n\n\n\n\n\nSeries.notin\n\n Series.notin (values)\n\n\n\n\nSeries.mapk\n\n Series.mapk (fun, **kwargs)\n\n\n\n\nDataFrame.sort\n\n DataFrame.sort (by, **kwargs)\n\n\ntemp = df.sample(df.len())\ntest_eq(temp.sort('col_1'), df)"
  },
  {
    "objectID": "core.html#move-columns-to-the-frontback",
    "href": "core.html#move-columns-to-the-frontback",
    "title": "core",
    "section": "Move columns to the front/back",
    "text": "Move columns to the front/back\n\n\nDataFrame.c2back\n\n DataFrame.c2back (cols2back)\n\n\n\n\nDataFrame.c2front\n\n DataFrame.c2front (cols2front)\n\n\ndf = dummydf()\n\n\ndf.c2back(['col_1'])\n\n\n\n\n\n  \n    \n      \n      col_2\n      col_1\n    \n  \n  \n    \n      0\n      a\n      100\n    \n    \n      1\n      b\n      101\n    \n    \n      2\n      c\n      102\n    \n    \n      3\n      d\n      103\n    \n    \n      4\n      e\n      104\n    \n  \n\n\n\n\n\ndf.c2back('col_1')\n\n\n\n\n\n  \n    \n      \n      col_2\n      col_1\n    \n  \n  \n    \n      0\n      a\n      100\n    \n    \n      1\n      b\n      101\n    \n    \n      2\n      c\n      102\n    \n    \n      3\n      d\n      103\n    \n    \n      4\n      e\n      104\n    \n  \n\n\n\n\n\ndf.c2front('col_2')\n\n\n\n\n\n  \n    \n      \n      col_2\n      col_1\n    \n  \n  \n    \n      0\n      a\n      100\n    \n    \n      1\n      b\n      101\n    \n    \n      2\n      c\n      102\n    \n    \n      3\n      d\n      103\n    \n    \n      4\n      e\n      104\n    \n  \n\n\n\n\n\ndf.c2front(['col_2'])\n\n\n\n\n\n  \n    \n      \n      col_2\n      col_1\n    \n  \n  \n    \n      0\n      a\n      100\n    \n    \n      1\n      b\n      101\n    \n    \n      2\n      c\n      102\n    \n    \n      3\n      d\n      103\n    \n    \n      4\n      e\n      104\n    \n  \n\n\n\n\n\n\n\nDataFrame.reorderc\n\n DataFrame.reorderc (to_front=[], to_back=[])\n\nReorder DataFrame columns.\n\ndf['col_3'] = df['col_1']\ndf.reorderc(['col_3'], ['col_1'])\n\n\n\n\n\n  \n    \n      \n      col_3\n      col_2\n      col_1\n    \n  \n  \n    \n      0\n      100\n      a\n      100\n    \n    \n      1\n      101\n      b\n      101\n    \n    \n      2\n      102\n      c\n      102\n    \n    \n      3\n      103\n      d\n      103\n    \n    \n      4\n      104\n      e\n      104"
  },
  {
    "objectID": "display.html",
    "href": "display.html",
    "title": "display",
    "section": "",
    "text": "DataFrame.title\n\n DataFrame.title (title)\n\nDisplays DataFrame with a title.\n\ndf = pd.DataFrame({'a': range(5), 'b': range(5)})\ndf.title('I am a table')\n\n\n\n\n\nsource\n\n\nWalker\n\n Walker (val=0, min_val=None, max_val=None)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nLess\n\n Less (df, page_size=5, page=1, where=None)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\nDataFrame.less\n\n DataFrame.less (page_size=5, page=1, where=None)\n\nDisplays one page of the DataFrame and buttons to move forward and backward.\n\ndf = pd.DataFrame({'a': range(17), 'b': range(17)})\ndf.less(page_size=7, page=2)\n\n\n\n\n\ndf.less(page_size=3, where=df.a.gt(5))\n\n\n\n\n\n\n\nSeries.less\n\n Series.less (page_size=5, where=None)\n\nDisplays one page of the Series and buttons to move forward and backward.\n\ns = pd.Series(range(7))\ns.less()\n\n\n\n\n\nsource\n\n\nL.less\n\n L.less (page_size=5, page=0, where=None)\n\nDisplays one page of the DataFrame and buttons to move forward and backward.\n\n\n\nDataFrame.to_percent\n\n DataFrame.to_percent (exclude=[])\n\nFormats float columns to percentage.\n\ndf = pd.DataFrame({'a': [0.1, 0.2], 'b': ['a', 'b']})\ndf.to_percent()\n\n\n\n\n  \n    \n       \n      a\n      b\n    \n  \n  \n    \n      0\n      10.0%\n      a\n    \n    \n      1\n      20.0%\n      b"
  },
  {
    "objectID": "case.html",
    "href": "case.html",
    "title": "case",
    "section": "",
    "text": "source\n\n\n\n replace_parentheses (s)\n\nReplaces __x__ by (x) in string s.\n\ntest_eq(replace_parentheses('hi__there__'), 'hi_(there)')\ntest_eq(replace_parentheses('hi__there____bye__'), 'hi_(there)_(bye)')\n\n\nsource\n\n\n\n\n snake2words (s)\n\nReturn properly capitalized version of snake_case string s\n\ntest_eq(snake2words('hi_bye__min__'), 'Hi Bye (min)')\n\n\nsource\n\n\n\n\n replace_acronyms (s)\n\nReplaces acronyms in s by its capitalized version.\nEdit the acronyms list as you wish.\n\n\nacronyms = ['MAE', 'RMSE', 'R2']\n\n\n\ntest_eq(replace_acronyms('foo mae Rmse r2'), 'foo MAE RMSE R2')\n\n\ntest_eq(replace_acronyms(['foo mae Rmse', 'rmse bar']), ['foo MAE RMSE', 'RMSE bar'])\n\n\nacronyms.append('X2YZ')\ntest_eq(replace_acronyms(['foo mae Rmse X2Yz', 'rmse bar']), ['foo MAE RMSE X2YZ', 'RMSE bar'])\n\n\ntest_eq(replace_acronyms('foomae'), 'foomae')\n\n\nsource\n\n\n\n\n if_instance (fun, t, x)\n\n\nsource\n\n\n\n\n snake2words_replace_acronyms (x)\n\n\nsource\n\n\n\n\n snake2words_replace_acronyms_if_str (x)\n\n\n\n\n\n\n DataFrame.rename2words (rename_index_name=True, rename_column_name=True)\n\nRenames columns in snake_case to Words.\n\ndf = pd.DataFrame({'var_x': range(3), 'mae__s__': range(3)}, index=pd.Index(range(3), name='index__m__'))\ndf.rename2words()\n\n\n\n\n\n  \n    \n      \n      Var X\n      MAE (s)\n    \n    \n      Index (m)\n      \n      \n    \n  \n  \n    \n      0\n      0\n      0\n    \n    \n      1\n      1\n      1\n    \n    \n      2\n      2\n      2\n    \n  \n\n\n\n\n\ndummydf().rename2words()\n\n\n\n\n\n  \n    \n      \n      Col 1\n      Col 2\n    \n  \n  \n    \n      0\n      100\n      a\n    \n    \n      1\n      101\n      b\n    \n    \n      2\n      102\n      c\n    \n    \n      3\n      103\n      d\n    \n    \n      4\n      104\n      e\n    \n  \n\n\n\n\n\nsource\n\n\n\n\n PxLabeler ()\n\nBehaves like a dictionary from snake_case –> Snake Case.\n\ntest_eq(px_labeler['foo'], 'Foo')\ntest_eq(px_labeler['position__m__'], 'Position (m)')\n\nSet the labels plotly argument to px_labeler.\n\ndf = pd.DataFrame({'time__s__': range(10), 'position__m__': range(10), 'speed__m/s__': 10*[1]})\nfig = express.scatter(df,x='time__s__', y='position__m__', labels=px_labeler)\nfig.show()"
  },
  {
    "objectID": "express.html",
    "href": "express.html",
    "title": "express",
    "section": "",
    "text": "import plotly.express as px\nfrom pdpatch.express import px"
  },
  {
    "objectID": "express.html#set_template",
    "href": "express.html#set_template",
    "title": "express",
    "section": "set_template",
    "text": "set_template\nSets plotly default template and updates its own doc string so you can always see your default template and options.\n/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Templates Configuration\n  else: warn(msg)\n\nsource\n\nset_template\n\n set_template (template_name)\n\n\nset_template('plotly')\ntest_eq(set_template.__doc__,\n        \"Templates configuration\\n-----------------------\\n    Default template: 'plotly'\\n    Available templates:\\n        ['ggplot2', 'seaborn', 'simple_white', 'plotly',\\n         'plotly_white', 'plotly_dark', 'presentation', 'xgridoff',\\n         'ygridoff', 'gridon', 'none']\\n\")\n\n\nset_template('seaborn')\ntest_eq(set_template.__doc__,\n        \"Templates configuration\\n-----------------------\\n    Default template: 'seaborn'\\n    Available templates:\\n        ['ggplot2', 'seaborn', 'simple_white', 'plotly',\\n         'plotly_white', 'plotly_dark', 'presentation', 'xgridoff',\\n         'ygridoff', 'gridon', 'none']\\n\")"
  },
  {
    "objectID": "express.html#fix-seaborn-template",
    "href": "express.html#fix-seaborn-template",
    "title": "express",
    "section": "Fix seaborn template",
    "text": "Fix seaborn template\nThe seaborn template sets the default line width to 0, making the invisible when using add_vline or add_hline methods. It also sets opacity to 0.5. We fix this by popping this keys and values from the seaborn template layout.\n\ndf = pd.DataFrame({'time_foo_bar_xyz__s__': range(10), 'position__m__': range(10), 'speed__m/s__': 10*[1]})\nfig = express.scatter(range(10), range(10))\nfig.add_hline(4)\nfig.add_vline(4)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\ndf = pd.DataFrame({'time_foo_bar_xyz__s__': range(10), 'position__m__': range(10), 'speed__m/s__': 10*[1]})\nfig = express.scatter(range(10), range(10))\nfig.add_hline(4)\nfig.add_vline(4)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "express.html#default-to-colorblind-palette",
    "href": "express.html#default-to-colorblind-palette",
    "title": "express",
    "section": "Default to colorblind palette",
    "text": "Default to colorblind palette"
  },
  {
    "objectID": "express.html#rename-snake_case-to-words",
    "href": "express.html#rename-snake_case-to-words",
    "title": "express",
    "section": "Rename snake_case to Words",
    "text": "Rename snake_case to Words\n\nsource\n\nupdate_legend_and_yaxis\n\n update_legend_and_yaxis (fun)\n\n\nsource\n\n\nExpress\n\n Express ()\n\nLike plotly.express but defaults to labels=px_labeler\n\nacronyms.append('XYZ')\n\n\ndf = pd.DataFrame({'time_foo_bar_xyz__s__': range(10), 'position__m__': range(10), 'speed__m/s__': 10*[1]})\npx.scatter(df, x='time_foo_bar_xyz__s__', y='position__m__').show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\ndf = pd.DataFrame({'time__s__': range(10), 'position__m__': range(10), 'speed__m/s__': 10*[1]})\nfig = px.scatter(df,x='time__s__', y=['position__m__', 'speed__m/s__'])\nfig.show(renderer=\"png\")\n\n\n\n\n\ndf = pd.DataFrame({'time__s__': range(10), 'position__m__': range(10), 'speed__m/s__': 10*[1]})\npx.imshow(df.crosstab(index='position__m__', column='time__s__')).show('png')\n\n\n\n\n\ndf = px.data.iris()\nfig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\", marginal_y=\"violin\",\n           marginal_x=\"box\", trendline=\"ols\", template=\"simple_white\")\nfig.show('png')\n\n\n\n\n\ndf = px.data.iris()\nfig = px.scatter_matrix(df, dimensions=[\"sepal_width\", \"sepal_length\", \"petal_width\", \"petal_length\"], color=\"species\")\nfig.show('png')\n\n\n\n\n\ndf = pd.DataFrame([\n    dict(task=\"Job A\", start='2009-01-01', finish='2009-02-28', resource=\"alex\"),\n    dict(task=\"Job B\", start='2009-03-05', finish='2009-04-15', resource=\"alex\"),\n    dict(task=\"Job C\", start='2009-02-20', finish='2009-05-30', resource=\"max\")\n])\n\nfig = px.timeline(df, x_start=\"start\", x_end=\"finish\", y=\"resource\", color=\"resource\")\nfig.show('png')\n\n\n\n\n\ndata = dict(\n    number=[39, 27.4, 20.6, 11, 2],\n    stage=[\"website visit\", \"downloads\", \"Potential customers\", \"Requested price\", \"Invoice sent\"])\nfig = px.funnel(data, x='number', y='stage')\nfig.show('png')\n\n\n\n\n\ndf = px.data.tips()\nfig = px.histogram(df, x=\"total_bill\", y=\"tip\", color=\"sex\", marginal=\"rug\", hover_data=df.columns)\nfig.show('png')\n\n\n\n\n\ndf = px.data.tips()\nfig = px.ecdf(df, x=\"total_bill\", color=\"sex\")\nfig.show('png')\n\n\n\n\n\ndf = px.data.iris()\nfig = px.density_heatmap(df, x=\"sepal_width\", y=\"sepal_length\", marginal_x=\"rug\", marginal_y=\"histogram\")\nfig.show('png')"
  },
  {
    "objectID": "express.html#altair-like-__add__-method",
    "href": "express.html#altair-like-__add__-method",
    "title": "express",
    "section": "Altair like __add__ method",
    "text": "Altair like __add__ method\n\ndf = pd.DataFrame({'time__s__': range(10), 'position__m__': [i**1.3 for i in range(10)], 'speed__m/s__': 10*[1]})\nfig = px.scatter(df,x='time__s__', y=['position__m__', 'speed__m/s__'])\nfig+px.scatter(df,x='time__s__', y='time__s__')\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n# fig1 / fig2\n\n\npx.scatter(df,x='time__s__', y='position__m__')+px.scatter(df,x='time__s__', y='speed__m/s__')\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nfig = px.scatter(df,x='time__s__', y='time__s__') + px.scatter(df,x='time__s__', y=['position__m__', 'speed__m/s__'])\nfig\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nfig = px.scatter(df,x='time__s__', y='time__s__') | px.scatter(df,x='time__s__', y=['position__m__', 'speed__m/s__'])\nfig\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nfig = px.scatter(df,x='time__s__', y='time__s__') / px.scatter(df,x='time__s__', y=['position__m__', 'speed__m/s__'])\nfig\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nfig = px.scatter(df,x='time__s__', y='time__s__') / px.scatter(df,x='time__s__', y=['position__m__', 'speed__m/s__'])\nfig | fig\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "seaborn.html",
    "href": "seaborn.html",
    "title": "seaborn",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nfrom pdpatch.core import *\n\n\nsource\n\nrenamer\n\n renamer (fun)\n\n\nsource\n\n\nSeaborn\n\n Seaborn ()\n\nLike express but renames all columns from snake_case to Words.\n\ndf = pd.DataFrame({'time__s__': range(10), 'position__m__': range(10)})\nsns.regplot(data=df, x='time__s__', y='position__m__');\n\n\n\n\n\ntips = sns.load_dataset(\"tips\")\nsns.relplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"day\");\n\n\n\n\n\nsns.relplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"day\", col=\"time\");\n\n\n\n\n\nsns.relplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"day\", col=\"time\", row=\"sex\")\n\n<seaborn.axisgrid.FacetGrid>\n\n\n\n\n\n\nsns.relplot(\n    data=tips, x=\"total_bill\", y=\"tip\", col=\"time\",\n    hue=\"time\", size=\"size\", style=\"sex\",\n    palette=[\"b\", \"r\"], sizes=(10, 100)\n)\n\n<seaborn.axisgrid.FacetGrid>\n\n\n\n\n\n\nfmri = seaborn.load_dataset(\"fmri\")\nsns.relplot(\n    data=fmri, x=\"timepoint\", y=\"signal\", col=\"region\",\n    hue=\"event\", style=\"event\", kind=\"line\",\n)\n\n<seaborn.axisgrid.FacetGrid>\n\n\n\n\n\n\nsns.relplot(\n    data=fmri,\n    x=\"timepoint\", y=\"signal\",\n    hue=\"event\", style=\"event\", col=\"region\",\n    height=4, aspect=.7, kind=\"line\"\n)\n\n<seaborn.axisgrid.FacetGrid>\n\n\n\n\n\n\ng = sns.relplot(\n    data=fmri,\n    x=\"timepoint\", y=\"signal\",\n    hue=\"event\", style=\"event\", col=\"region\",\n    height=4, aspect=.7, kind=\"line\"\n)\n(g.map(plt.axhline, y=0, color=\".7\", dashes=(2, 1), zorder=0)\n  .set_axis_labels(\"Timepoint\", \"Percent signal change\")\n  .set_titles(\"Region: {col_name} cortex\")\n  .tight_layout(w_pad=0))\n\n\n\n\n\nflights_wide = sns.load_dataset(\"flights\").pivot(\"year\", \"month\", \"passengers\")\nsns.relplot(data=flights_wide, kind=\"line\")\n\n<seaborn.axisgrid.FacetGrid>\n\n\n\n\n\n\npenguins = sns.load_dataset(\"penguins\")\nsns.displot(data=penguins, x=\"flipper_length_mm\");\n\n\n\n\n\n# import seaborn as sns;\nsns.set_theme(color_codes=True)\ntips = sns.load_dataset(\"tips\")\ng = sns.lmplot(x=\"total_bill\", y=\"tip\", data=tips);\n\n\n\n\n\ng = sns.lmplot(x=\"total_bill\", y=\"tip\", col=\"day\", hue=\"day\",\n               data=tips, col_wrap=2, height=3);\n\n\n\n\n\nflights = sns.load_dataset(\"flights\")\nflights = flights.pivot(\"month\", \"year\", \"passengers\")\nax = sns.heatmap(flights);\n\n\n\n\nIf you use sns.FacetGrid you will have to use the Word version of the column names in the method map and map_dataframe.\n\ntips = sns.load_dataset(\"tips\")\ng = sns.FacetGrid(tips, col=\"time\",  row=\"sex\")\ng.map(sns.scatterplot, \"Total Bill\", \"Tip\");\n\n\n\n\n\ng = sns.FacetGrid(tips, col=\"time\",  row=\"sex\")\ng.map_dataframe(sns.histplot, x=\"Total Bill\");"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "pdpatch",
    "section": "",
    "text": "Below we outline what’s involved in different aspects of contribution.\n\n\nIn order to accept your pull request, we need you to submit a CLA. Once you complete your CLA, then it is valid for all future contributions you make to this repository.\nComplete your CLA here: CLA Form\n\n\n\nBefore anything else, please install the git hooks that run automatic scripts during each commit and merge to strip the notebooks of superfluous metadata (and avoid merge conflicts). After cloning the repository, run the following command inside it:\nnbdev_install_git_hooks\n\n\n\n\nEnsure the bug was not already reported by searching on GitHub under Issues.\nIf you’re unable to find an open issue addressing the problem, open a new one. Be sure to include a title and clear description, as much relevant information as possible, and a code sample or an executable test case demonstrating the expected behavior that is not occurring.\nBe sure to add the complete error messages.\n\n\n\n\nOpen a new GitHub pull request with the patch.\nEnsure that your PR includes a test that fails without your patch, and pass with it.\nEnsure the PR description clearly describes the problem and solution. Include the relevant issue number if applicable.\n\n\n\n\n\n\nKeep each PR focused. While it’s more convenient, do not combine several unrelated fixes together. Create as many branches as needing to keep each PR focused.\nDo not mix style changes/fixes with “functional” changes. It’s very difficult to review such PRs and it most likely get rejected.\nDo not add/remove vertical whitespace. Preserve the original style of the file you edit as much as you can.\nDo not turn an already submitted PR into your development playground. If after you submitted PR, you discovered that more work is needed - close the PR, do the required work and then submit a new PR. Otherwise each of your commits requires attention from maintainers of the project.\nIf, however, you submitted a PR and received a request for changes, you should proceed with commits inside that PR, so that the maintainer can see the incremental fixes and won’t need to review the whole PR again. In the exception case where you realize it’ll take many many commits to complete the requests, then it’s probably best to close the PR, do the work and then submit it again. Use common sense where you’d choose one way over another.\n\n\n\n\n\nDocs are automatically created from the notebooks in the nbs folder."
  }
]